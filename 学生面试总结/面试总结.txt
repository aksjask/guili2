MQ
	1.为什么使用MQ?
	使用MQ的好处:解耦,异步和削峰;
		解耦,当A系统生产关键数据,而且B,C,D系统需要A系统给它们发送数据,来进行下一步操作,此时A系统和BCD系统产生了严重的耦合,所有的操作和维护都要在A系统中进行,如果将A系统产生的数据放到MQ当中,让BCD系统需要的时候去消费,此时就解放了A系统,不用考虑调用成功,失败超时等情况,同时ABCD系统独立运行,后续新添加系统需要A系统的数据,也不需要去修改A系统的代码,达到了解耦的效果
		
		我们项目中搜索服务系统和页面生成系统依赖运营商后台系统中发送的数据,来进行搜索的生成和和静态页面的生成,此时产生了严重的耦合,所以将运营商后台生成的数据放到ActiveMQ中,让搜索服务系统和页面生成系统需要时去消费,后台系统就不用管下游系统的结果,达到解耦的效果,其次是商品通过盛和,就要把商品信息导入索引库,商品删除就要把商品从索引库移除,这是一个耗时的过程,如果同步执行代码的话产生等待效果,影响用户的体验,还有对于广告首页内容的修改也采用这样的策略,运营商修改完广告内容就不必等首页内容更新完了,这是个耗时的过程.还有就是商品审核通过后,执行对商品详情页的网页静态化,因为考虑到商品详情页部署在多个nginx上,所以采用topic类型的消息,保证每个nginx都要有一淘相同的商品详情页
		
		异步
		一般互联网类企业,对用户的直接操作,一般要求每个请求在200ms以内完成
		对于一个系统调用多个系统,在不适用mq的情况下,它执行完返回的耗时,是执行完所有系统所需时间的总和;使用mq进行优化后,执行的耗时,则是执行主系统的耗时,以及加上主系统发送数据到消息队列的耗时,大幅度提升高延时接口的性能,提升了用户体验.
		
		削峰
		一般MySQL的每秒请求最高在2000左右
		用户访问量高峰期的时候涌入的大量请求,很可能将MySQL给打死,然后系统就挂掉,但是高峰期过了,请求量可能远远低于2000,所以这种情况去增加服务器就不值得,如果使用mq的情况,将用户的请求全部放到mq中,然后让系统去消费用户的请求,不要超过系统所能承受的最大请求数量,保证系统不会再高峰期挂掉,但此时可能有几十万或几百万请求积压在mq中,但是高峰期一过,系统还是按照最大请求数量进行处理请求,很快就能将积压请求处理完
		
	使用MQ的缺陷:
		系统可用性降低:以前只要担心系统的问题,现在还要考虑mq如果挂掉的问题,因为mq一旦挂掉,所关联的系统,就会统统挂掉
		系统复杂性变高:考虑的问题变多,要考虑消息丢失,消息重复消费的情况
		一致性问题:比如A系统调用BCD系统,BCD同时成功才能执行成功,返回数据,现在BC执行成功,D发生异常的情况,并没有执行成功,但是A给用户返回的是成功
		
		
	2.ActiveMQ,RabbitMQ,RocketMQ,kafka
		ActiveMQ它可以支持万级的吞吐量,它是一个比较成熟完善的中间件,但是它存在有少量信息丢失的情况,而且目前官方对他的更新迭代不是很即时,社区的活跃度不是很高
		RabbitMQ是一款用Erlang语言开发的消息中间件,它延时低,唯一一款达到微妙级延时的消息中间件,而且社区活跃度高,对于bug问题的修复很及时,而且提供了很友善的后台界面,唯一的劣势是就是我们搞java开发的很少有人能够阅读它的源码,对于问题的修复仅仅依靠社区
		RocketMQ是阿里旗下的一款品质优秀的MQ,它可以达到十万级的吞吐量,而且它还是支持分布式事务,应用于分布式架构,它的维护基本上都是靠阿里,如果哪天阿里宣布放弃这个项目的维护,除非你们公司有能力继续来维护RocketMQ的使用
		Kafka也是一款分布式的中间件,最大优点就是其吞吐量高,一般运用于大数据系统的实时运算和日志采集的场景,功能简单,可靠性高,扩展性高,唯一的缺点是可能导致重复消费,但是这点轻微的影响在大数据场景下可以忽略
	
	
	3.如何保证MQ的高可用?
		非分布式的MQ的高可用:
			普通集群模式:实际queue保存在一个节点上,其他节点保存该queue的元数据,消费者连接某个节点,该节点去调用实际存放queue的节点,返回数据,说白了只是简单的提高了吞吐量而已.缺陷在于:在集群内部产生大量的数据传输,高可用性没有,queue所在的节点宕机,服务就没法继续使用
			镜像集群模式:每个节点上都保存了实际的queue的全部数据,消费者无论连接哪个节点,都能直接获取到数据.任何一个节点宕机,其他节点还存在queue的全部数据,消费者换个节点继续消费,这是高可用的模式
		
		分布式MQ的高可用:
			假设生产者往topic里写了三条数据,每条数据放在一个partition中,每个partition部署在一台机器中,每个partition都有一个或多个replica副本,其中有一个是leader,其他的是follower,只有leader能够向外提供数据的读写,生产者写入消息时,leader负责向follower同步消息,此时高可用架构就已经体现,如果一台leader宕机,会从它的follower中选举一个leader,继续向外提供服务
			
	4.如何保证消息不被重复消费(如何保证消息消费时的幂等性)?
		重复消费:
		每个中间件它能够保证的是消息不丢失,不能保证消息不被重复发送.比如在卡夫卡中,每个消息写进来只是都有一个offset代表序号,然后消费者消费数据,每隔一段时间,都会通过zookeeper把自己消费过的消息的offset提交一下,代表已经消费过的,下次重启,就从上次消费到的offset继续消费,如果,在offset还未提交之前消费者系统就被重启,就会发生重复消费的现象
		
		消费的幂等性:
		1. 如果是往数据库里写入数据,就根据主键查一下,如果数据已经存在,就update
		2. 可以在把数据先存在set或者redis中,消费前,先去里面查看,数据是否已存在,已存在就丢弃这数据,比如说我们的订单系统,生成订单也会用到mq,此时订单id就是全局唯一的id,在写入数据库之前,就可以先把数据去redis中查询,如果redis中已经存在,则不进行消费操作,如果redis中不存在的话,就存在redis中,然后进行下一步操作.
		3. 在数据库中设置唯一约束,就不会导致重复数据的多次插入
		
	5.如何保证消息不丢失
	rabbit:
		消息丢失的情况:
			生产者写的消息在到中间件的网络传输过程中就丢了,或者是消息到了中间件,但是内部出错,消息没保存下来
			中间件将消息保存下来,还没等到消费者消费完,就自己挂掉,导致消息丢失
			消费者取到消息还没来得及消费就自己挂掉了,因为rabbitMQ消费者开启了autoAck,在消费数据还没成功时,就已经向中间件发送完成的信息,此时消费者挂掉,就会消息丢失
		
		解决方案:
		生产者消息丢失,可以通过开启事务功能,如果消息没有发送成功,发生异常就回滚,然后重试发送消息,发送成功就提交事务,这个的缺陷就是阻塞式的,降低吞吐量,耗费性能;如果是rabbitMQ可以开启confirm模式,它能u二宝每次写的消息都会分配一个唯一的id,如果写入到rabbitMQ中,rabbitMQ就会回传一个ack消息,如果没有就会会挑一个nack接口,告诉你消息接收失败,你可以重试,confrim机制是异步的,效率会高很多
		关于中间件的数据丢失,可以开启中间件的持久化,将消息持久化磁盘中,中间件挂了恢复之后自动读取之前存储的数据.
		消费者数据丢失,关闭rabbitMQ的autoACK机制,自己手动提交完成信息
		
	kafka:
		丢失数据的情况
		消费端:可能打开自动提交offset,让kafka以为你已经消费完成,可是还没处理完,消费端就挂了
		kafka:某个leader挂了,有其他follower刚好数据没同步完成,此时这个follower被选举成为leader就会缺少部分消息
		
		解决方案:
		1.给topic设置replication.factor参数,值必须大于1,要求每个partition必须有至少两个副本
		2.在kafka服务端设置min.insync.replicas参数:值必须大于1,要求一个leader至少有一个follower还跟自己保持一致,这样保证leader改了之后还有一个follower
		3.在producer端设置acks=all:要求每条数据,必须是写入所有replica副本之后,才算写成功
		4.producer端设置retries=max(很大的值,无限重试的意思),要求一旦写入失败,就在这儿无限重试,直到成功(保证生产者不会丢失消息)
		
	
	6.如何保证消息的顺序性
		应用场景:MySQL数据库的binlog同步,要保证操作的顺序
		
		rabbitMQ为多个消费者开辟多个queue队列,将保证操作顺序的消息发布到同一个队列中去
		
		kafka可以保证写入到一个partion中的数据一定是有顺序的,生产者在写数据时,可以指定一个key,比如指定某个订单的id为key,这个订单相干的数据一定会被分发到一个partition中去,一个消费者只能消费一个partition,这样就能保证从partition中取出来的数据是有顺序的;如果消费者内部开启多线程去处理数据,就可能出现操作顺序错乱的情况;为每个线程开辟一个内存队列,使用hash算法,进行hash分发,将同一个key的数据分发到同一个内存队列中
		
	7.积压几百万条消息在消费中间件中怎么办?(消息延时以及过期失效的问题)
		消费端出现问题
			
		解决方案:
		1.先修复消费端的问题,确保其回复消费速度,然后将先后的消费者都停掉
		2.仙剑一个topic,partition是原来的10倍,临时建立号原先10倍的quueue数量
		3.然后写一个临时的分发数据的消费程序,这个程序部署上去去消费积压的数据,消费之后不做耗时的处理,直接均匀轮询写入临时建立号的10倍数量的queue
		4.接着临时征用10倍的机器来部署consumer,每一批consumer消费一个临时queue的数据
		5.等快消费完积压数据只有,回复原先的部署架构,重新用原先的consumer机器来消费消息
		
		
		rabbitMQ消息可以设置过期时间导致消息过期失效问题
		解决方案:写程序讲丢失的数据,一点点查出来,然后重新写入到mq里面,将丢失的数据补回来
		
		消息积压导致mq磁盘快要满了的问题
		解决方案:临时写程序,接入数据消费,消费一个丢弃一个,然后再执行补数据的方案
		
	
tips
	消息中间件:在消息队列服务器中用于过滤,区分和根据规则进行转发的程序
	消息队列:利用高效可靠的消息传递机制进行与平台无关的数据交流,并基于数据通信进行分布式系统的集成,消息传输过程中保存消息的容器
	
	
	
分布式搜索:
	数据分类:结构化和非结构化
		结构化数据是有规律的,通常都是使用sql语句进行查询,而且能很快得到查询结果
	
	非结构化数据查询方法:
		1.顺序扫描法:查找内容包含某个字符串的文件,就是挨个文档挨个文档的看,从头看到尾,知道扫描完所有的文件,才能找到所需要的文件,,非常缓慢
		
		2.全文检索:
		索引:从非结构化数据中提取出来然后重新组织的具有一定结构的信息
		先建立索引,然后在对索引进行搜索的过程叫做全文检索
		
	倒排索引
		原理:先抽取文档中的词,并建立词与文档ID的映射关系,然后查询的时候会根据词去查询文档id,并查出文档
		倒排索引被用来存储在全文搜索情况下,莫格单词在一个文档或者一组文档中存储位置的映射
		
	Lucene
		apache下的一个开源的全文检索引擎工具包,提供了完整的查询引擎和索引引擎,部分文本分析引擎
		
	solr
		1. 是一个开源的搜索平台,用于构建搜索应用程序
		2.它的原理是基于lucene开发的全文检索服务器,而lucene就是一淘实现了全文检索的api,其本质就是一个全文检索的过程
		3.全文检索就是把原始文档根据一定的规则拆分成若干个关键词,然后根据关键词创建索引,当查询时先查询索引找到对应的关键词,并根据关键词找到对应的文档,也就是查询结果,最终把查询结果展示给用户的过程
		
	solr设置搜索结果排名靠前
		可以设置文档中域的boost值,boost值越高,计算出来的相关度得分就越高,排名也就靠前,我们系统中主要将这个运用到热点产品中和推广商品的排名提高上
		
	solr中ik分词器的原理
		本质上就是词典分词,在内存中初始化一个词典,然后再分词过程中逐个读取字符,和字典的字符相匹配,把文档中的所有词拆分出来的过程
	
	solr的索引查询为什么比数据库快
		solr使用的lucence API实现的全文检索,本质上查询的是索引,而数据苦衷不是所有字段都建立了索引,而且如果使用like查询时很大可能时不适用索引的,所有solr查询要比查数据库快
		
	多张表的数据导入solr,id冲突问题
		再schema.xml添加uuid,然后solrconfig那边修改update的部分,改为uuid生成
		
	solr如何分词,新增词和禁用词如何解决
		schema.xml文件中配置一个IK分词器,然后域指定分词为ik,新增词添加到词典配置文件ext.dic中,禁用词添加到词典配置文件stopword.dic中,然后再schema.xml文件中配置禁用词典即可
		
	solr多条件组合查询
		创建多个查询对象,指定他们的组合关系,Occur.MUST(and的意思),Occur.SHOULD(or的意思),Occur.MUST_NOT(not的意思)
		
redis缓存
	项目中使用缓存,是怎么使用过的?
		首先,我负责的首页广告模块,因为考虑到这是整个项目的门面模块,访问量是巨大的,而且它变化的内容不太大.所以在这里使用了缓存技术,在用户访问首页时,先去缓存中查询数据,如果缓存中没有数据,就去数据库中查询,获得数据,然后将数据存入到redis缓存当中,再将数据放回到页面展示.后续的访问就可以去缓存中查询到数据,而不用去查询数据库,提高了执行性能和效率,提升用户的体验
		还有,我负责的购物车模块也是将购物车也是放到redis缓存中的,这样就不用在数据库中生成购物车的表,就能防止客户恶意向购物车里添加商品来导致不断地去执行数据库操作,最终导致数据库崩溃这一情况;还用从redis中查询购物车从缓存中查询要比从数据库中快多了
		
	使用缓存的好处
		高并发,高性能
	
	使用缓存的弊端
		缓存穿透
		缓存雪崩
		缓存数据库双写不一致
		缓存并发竞争
		
	redis和memcached的区别
		1.redis支持更丰富的数据操作,数据类型比memcached更多
		2.redis是单线程,memcached是多线程
		3.redis有原生的集群模式,memcached没有原生的集群模式
		
	为什么redis是单线程的但是还可以支撑高并发?
		redis模型:单线程,nio,异步的线程模型.redis里有个处理器叫做文件事件处理器(file event handler),这个文件事件处理器是单线程的,redis所以是单线程的模型,它采用io多路复用机制同时建通多个socker.根据socket上的事件选择对应的事件处理器来处理时间
		
		执行流程:
		1.redis启动初始化时,redis会将连接应答器和AE_READABLE事件关联
		2.客户端跟redis连接,会在serverSocket产生一个AE_READABLE事件,然后由IO多路复用程序监听到事件,将serverSocket压入队列,然后连接应答处理器来处理事件,和客户端建立连接,创建对应的socket,同时将这个socket的AE_READABLE事件跟命令请求处理器关联起来
		3.客户端向redis发起请求时,首先会在socket中产生一个AE_READABLE事件,然后被监听,被压入队列,然后由对应的命令请求处理器来处理
		4.redis准备好给客户端响应数据之后,就会将socket的AE_WRITABLE命令跟回复处理器关联起来,当客户端准备好读取响应数据时,就会在socket上产生一个AE_WRITABLE事件,会由对应的命令回复处理器来处理
		5.命令回复处理器处理完之后,就会删除这个socket的AE_WRITABLE事件和命令回复处理器的关联关系
		
		为什么效率高?
		1.核心是基于非阻塞的IO多路复用机制,由监听程序轮询等待的事件,然后压入队列,可以达到一个线程同时处理多个io请求的目的
		2.纯内存操作
		3.单线程避免了多线程的频繁上下文切换问题
		
	
	redis由哪些数据类型,分别在哪些场景下使用?
		String,存储基本的类型
		
		List,有序列表,比如之前项目中的广告缓存,用的就是list集合进行缓存的,它可以用于比如存储粉丝列表,文章的评论列表等等
		
		Set,无序列表,它最主要的特点就是去重,比如微博上查询两个明星的共同粉丝,就可以用set进行去重 sinter
		
		SortedSet,它主要是在set的基础上加上了排序,zadd board score username,zrevrange board 0 99
		Hash,类似map的集合,一般可以用来存储对象,我们系统中的购物车对象就是以hash类型存储在redis中,key就是用户的id,value就是购物车对象
		
	
	redis过期策略
		定期删除+惰性删除
		定期删除,指的是redis默认每个100ms就抽取一些设置了过期事件的key,检查是否过期,如果过期就删除.如果太多的key都设置了过期时间,每隔几百毫秒,就全部检查删除,cpu的负载会很高.实际上redis是每隔100ms随机抽取一些key来检查和删除.
		惰性删除,就是当你获取莫格key时,redis就会检查一下,如果key过期了,就删除,不会返回,如果没过期就返回
		
		因为redis的过期策略会导致你设置了过期key,过期了很多过期key没有被删除,还堆积在内存中,此时就要设置内存淘汰机制来解决了
		
	内存淘汰机制
		1.noevication:当内存不足以容纳写入新数据时,新写入操作就会报错
		2.allkeys-lru:当内存不足以容纳新写入数据时,在键空间中,移除最近最少使用的key
		3.allkeys-random:在键空间中,随机移除某个key
		4.volatile-lru:在设置了过期时间的键空间中,移除最近最少使用的key
		5.volatile-random:在设置了过期时间的键空间中,随机移除某个key
		6.volatile-ttl:在设置了过期时间的键空间中,由更早过期时间的key优先移除
		
		
	怎样做到redis支撑高并发(请求读多写少用缓存,读少写多用队列)
		搭建redis集群,做成主从架构,一主多从,通过redis replication机制实现读写分离,主负责写,并且将数据同步复制到其他slave节点上,从节点负责读,所有的读请求走从节点.好处,可支持水平扩容的读高并发架构 
		
	redis replication的核心机制
		1.redis采用异步方式复制数据都slave节点上,slave节点会周期性的确认自己每次复制的数据量
		2.一个master节点可以配置多了slave节点
		3.slave节点也可以连接其他slave节点
		4.slave节点做复制的时候,是不会block master节点的正常工作的
		5.slave节点做复制的时候,也不会block对自己的查询操作,它会用旧数据向外提供服务;复制完后,它就删除旧数据,加载新数据,这个时候向外停止服务(毫秒级别)
		6.slave节点主要用来横向扩容,做读写分离,提高吞吐量4
		
	master持久化对于主从架构的安全保障的意义
		如果仅仅用slave节点作为master节点的数据热备份,当master节点宕机后重启,数据清空,本地没有数据可以恢复,它会任为自己的数据就是空的,然后同步到slave节点上,就会导致数据百分百丢失
		其次,如果开启了哨兵机制,在master节点挂掉之后,会迅速推选出一个slave节点去做master节点,但是当哨兵还没检测到master节点挂掉,master节点就自动重启了,还是会出现上面的情况
		
		
	redis主从架构的核心原理
		1.当启动一个slave节点时,会发送一个PSYNC命令给master节点
		2.如果这个slave节点第一次连接master节点,就会出发full resynchronization
		3.开始full resynchronization的时候,master会开启一个后台线程,开始生成一份rdb快照文件,同时还还会继续接收客户端的写命令,存在内存中.RDB文件生成完毕后,master会将这个RDB发送给slave,slave先将RDB写入本地自盘,然后再加载到内存.然后master会将内存中缓存的写命令发送给slave,slave同步这些数据
		
		tips:如果发生网络故障,所有slave节点和master节点断开连接,发生重连,master就会启动一个rdb save的操作,用一份数据服务所有的slave接待
		
	redis主从复制的断点续传
		redis从2.8开始就支持断点续传.master节点会在内存中创建一个backlog,master节点和slave节点都会保存一个replica offset还有一个master id,offset保存再backlog(用于全量复制中断后的增量复制)中,如果master和slave网络连接中断,slave会让master从上次的replica offset开始继续复制,如果没有找到对应的offset,那么就会执行full resynchronization操作
	
	redis主从复制的过期key处理
		slave不会过期key,指挥等待master过期key,如果masetr过期一个key,或者通过lru机制淘汰一个key,就会模拟一条del命令发送给slave
		
	redis的高可用
		不可用:虽然主从架构,读写分离可以保证缓存应对高并发场景,但是如果master节点挂掉,整个缓存架构就会挂掉,大量的流量涌入数据库,超过数据库的最大承载压力,数据库挂掉,整个系统就会挂掉不可用
		高可用:故障转移,主备切换,当master故障时,自动检测(通过sentinal node 哨兵),将某个slave自动切换成master的过程交主备切换.这个机制实现了redis主从架构下的高可用性
		
		
	redis哨兵(sentinal)
		1. 集群监控,负责监控redis master 和slave进程是否正常工作
		2. 消息通知,如果莫格redis实例由故障,那么哨兵负责发送消息作为警报通知给管理员
		3.故障转移,如果master挂掉,自动转移得到slave节点上
		4.配置中心,如果故障转移发生了,通知客户端新的master地址
		
	tips
		1.哨兵本身也是分布式的,作为一个哨兵集群去运行,至少得三个实力,才能保证自己的健壮性
		2.哨兵+redis主从架构,只能保证redis集群的高可用性,不能保证数据的零丢失
		
	为什么哨兵集群至少要三个节点
		如果只部署两个,部署再一个master和slave上,当master挂掉时,虽然哨兵能够检测到,但是执行故障转移需要majority,2的majority还是2
		,此时master上的哨兵已经宕机了,只剩下slave节点上一个哨兵,无法被允许执行故障转移
		
	异步复制导致数据丢失问题
		master节点给从节点异步复制数据时,此时自己还在接收客户端的写入请求,缓存在内存中,此时master挂掉,哨兵就会立即推选slave节点切换为master节点,就会导致这些缓存再内存中的数据丢失
		
	脑裂问题导致数据丢失问题
		master节点与slave节点发生故障,导致master被孤立再集群外,此时哨兵集群就提拔某个slave节点作为master节点,而客户端还未来得及切换到新的master,继续向原来的master发送写请求.最后网络故障被修复,原来的master变为slave,同步现在的master数据,那么故障之后的客户端数据就丢失了
	
	解决方案:
		min-slaves-to-write 1
		min-slaves-max-lag 10
		
		要求至少有一个slave,数据复制和同步的延时不能超过10秒.超过10秒,master就拒绝接收客户端任何请求,把丢失数据降低到可控范围.客户端可以将数据存入消息队列中,或者尝试发送给其他master
	
	redis持久化的意义
		如果没有持久化,遇到灾难性故障时,就会丢失所有数据
		如果开启持久化到磁盘,定期备份到云服务上,就能保证遇到灾难性故障,就不会丢失全部数据
		
	RDB
		当redis需要做持久化时,redis会fork一个子进程,将数据写到磁盘写上一个临时RDB文件中,当子进程完成写临时文件后,将原来的RDB换掉
		
		优势:
		1.适合做冷备份,在最坏的情况下,恢复数据要比AOF快
		2.对redis对外提供读写服务,影响服务非常小
		3.RDB数据快照文件更少
		
	AOF
		可以做到更精细的持久化,redis每执行一个修改数据的命令,都会将它添加到os cache中,一般会每个一秒执行一次fsync操作,保证将os cache中的数据写入磁盘中AOF日志文件中,AOF日志文件以append-only模式写入,文件不容易破损,在AOF日志过大时,就会出现后台重写
		
		优势:
		1.AOF可以更好的保护数据不丢失,丢失的数据更少
		2.AOF日志文件以append-only模式写入,没有磁盘寻址的开销,写入性能非常高
		3.AOF日志过大时,也不会影响客户端的读写
		
	RDB和AOF到底如何抉择
		综合使用两种持久化机制,用AOF保证数据不丢失,作为数据恢复的第一选择,用RDB来做不同程度的冷备份,在AOF文件丢失或者损坏不可用的情况下,用RDB来进行快速的数据回复
		
	redis支撑海量数据+高并发+高可用
		reids cluster (多master + 读写分离 + 高可用)
		支撑N个redis master node,每个master node都可以挂在多个slave node
		读写分离的架构,对于每个master来说,写就写到master,然后	读就去slave去读
		高可用,因为每个master都有slave节点,如果master挂掉,redis cluster就会自动将某个slave切换成master
		我们只要基于redis cluster去搭建redis集群即可,不需要手工去搭建replication复制+主从架构+读写分离+哨兵集群
		
	redis cluster底层原理
	//TODO
	
	
	缓存雪崩
		缓存雪崩的场景:缓存所在的机器宕机,访问高峰期大量的并发请求,
		直接去访问数据库,导致数据库直接崩溃,然后系统直接瘫痪.如果没有应急方案,dba重启数据库立即就被新的流量给打死
		
		解决方案:
		事前:保证redis集群的高可用性,redis cluster,主从机制+哨兵;
		事中:本地ehcache缓存+hystrix限流+降级,避免数据库被打死.系统内部本地建立ehcache,用户请求先去查询ehcache,ehcache中没有再去查询redis,如果还没有,就去查询数据库,查询结果在写入redis和ehcache;高并发的访问量走hystrix限流组件,让访问量保持在数据库最大负载范围内,保证数据库不被打死,系统可以继续使用.剩余的请求走降级组件,返回一些默认的值或者是友情提示等
		事后:redis持久化机制,尽快回复缓存集群,一旦重启,自动从磁盘上加载数据,回复内存中的数据
		
		tips:ehcache是一个纯java的进程内缓存框架,具有快速,精干等特点,事Hibernate中默认的cacheProvider
		
	缓存穿透
		场景:大量的请求访问,查询的是数据库中不存在的数据,就会在缓存中无法命中,直接去访问数据库,数据库中也查询不到,自然无法将结果写入缓存,下一秒又有大量请求查询不存在的数据,导致数据库最终挂掉(要么系统出bug,要么黑客恶意攻击)
		
		解决方案:在数据库中没有查询到的数据,存储一个特定值到缓存中,这样下次恶意访问就可以去缓存中查询到数据,不会访问到数据库.主义的是这些特定值数据,设置过期key
		
		
	缓存数据库的双写一致性
		经典的缓存+数据库读写的模式,cache aside pattern
			1.读的时候,先读缓存,缓存没有就去都数据库,然后取出数据放入缓存,同时响应
			2.更新的时候,先删除缓存,再更新数据库
			
		为什么是删除缓存,而不是更新
			因为更新缓存的代价很高,有的数据你可能进行频繁的修改,而去查询的次数不多
			
		
		1.最初级的缓存不一致:
		先修改数据库,再删除缓存,如果删除缓存失败,就会导致数据库中式新数据,缓存中是旧数据,数据不一致
		
		解决思路:
		先删除缓存,再删除数据库,如果删除缓存成功,修改数据库失败,那么数据库中是旧数据,缓存中是空的,读的时候缓存中没有,去数据库中读旧数据,然后更新到缓存中去
		
		
		2.比较复杂的数据不一致:
		读写并发请求,导致数据库和缓存中的数据不一致,在写请求删除缓存,修改数据库库存还未成功时,查询库存的请求就发来,先去缓存中查询,发现是空,然后去数据库中查,然后将结果放入缓存中,然后修改库存的操作成功,导致数据库中是新数据,缓存中是旧数据
		
		3.高并发场景下数据库与缓存的数据不一致:
		相同的商品id,进行哈希取值,再加上对内存队列的数量进行取模,每个商品都可以路由到某一个内存队列中,然后将去请求和写请求串行化,这样就可保证一定不会出现不一致的情况,但是会导致系统的吞吐量会大幅降低
		
		
	redis的并发竞争问题
		分布式锁,确保同一时间,只能由一个系统实例在操作某个key,别的实例不被允许读和写,每次要写之前,先判断这个value的时间戳是否比缓存里的更新,如果新就允许写.
		

分布式系统
	dubbo:是阿里开源的一个分布式服务框架,主要使用rpc远程调用协议进行远程调用,直接使用socket通信的服务治理方案,使用dubbo可以实现透明化的远程方法调用,负载均衡,服务自动注册与发现,超时重试等乱七八糟的问题
	
	
	为什么要把系统拆分
		多人维护一个大模块的代码,各种修改各种冲突各种报错,很痛苦;拆分成一个个小模块后,每个人只要负责自己的模块,自己模块里面的技术升级,不用考虑其他模块,测试也只要测试自己的模块即可
		
	如何拆
		拆多轮,不是一次拆到位,如果发现一个服务需要三到五个人去维护,那么这个服务就可以进行拆分了,理想状态是一个人维护一到三个服务
		
	dubbo的工作原理
		service层:接口层,provider和consumer需要自己实现
		config层:配置层,对dubbo进行各种配置的
		proxy层:服务代理层,无论consumer还是provider,dubbo都会给你生成代理,代理之间进行网络通信
		registry层:服务注册层,provider注册自己为一个服务,consumer可以去注册中新寻找自己要调用的服务
		cluster层:集群层,provider可以部署在多台级上,多个provider就组成了一个集群,封装多个服务提供者的路由以及负载均衡
		monitor层:监控层,统计信息监控,对rpc接口的调用次数和调用时间进行监控
		protocol层:远程调用层,负责具体的provider和consumer之间调用接口的时候的网络通信
		exchange层:信息交换层,封装请求相应模式,同步转为异步
		transport层:网络传输层,抽象mina和netty为统一接口
		serialize层:数据序列化层
		
		
	工作流程
		1.provider向注册中心去注册自己为一个服务
		2.consumer去注册中心订阅服务,注册中心会通知consumer注册好的服务,consumer会将provider的地址等信息拉取到本地缓存
		3.consumer去调用provider
		4.consumer和provider都异步的通知监控中心
		
	注册中心挂了可以继续通信吗?
		可以,因为刚开始初始化的时候,消费者会将提供者的地址等信息缓存到本地,注册中心挂了可以继续通信
	
	dubbo支持哪些通信协议,支持哪些序列化协议?
		dubbo协议(dubbo://ip:port)
			默认就是dubbo协议,单一的长连接,NIO异步通信,基于hessian(跨语言,较慢)作为序列化协议
			使用场景:传输数据量很小(每次请求在100k以内),并发量很高
			
		rmi协议
			走java二进制序列化,多个短链接,适合消费者和提供者数量差不多,用于文件的传输,一般比较少用
			
		hessian协议
			走hessian序列化协议,多个短链接,适用于提供者比消费者数量还多的场景,适用于文件的传视,一般较少用
			
		http协议
			走json序列化协议
			
		webservice
			走SOAP文本序列化协议
			
			
	dubbo负载均衡策略有哪些?
		1.random loadbalance
			默认情况下,dubbo是random loadbalance随机调用实现负载均衡,可以对provider不同实例设置不同的权重,会按照权重来负载均衡,权重大分配的流量高
			
		2.roundrobin loadbalance
			默认就是均匀地将流量达到各个机器上,值得注意的是,要根据机器的性能,调整权重
			
		3.leastactive loadbalance
			dubbo自动感知,如果某个机器性能越差,那么接收的请求就越少,给不活跃的机器更少的请求
			
		4.consistanthash loadbalance
			一致性hash算法,相同参数的请求一定分发到同一个provider上,provider挂掉的时候,会基于虚拟机节点均匀分配甚于的流量,抖动不会太大.适用于订单,同一个订单的操作,分配到同一个机器上,这样就可以高并发场景下,数据库和缓存中数据不一致的情况
			
			
	dubbo集群的容错策略
		1.failover cluster模式(默认)
			失败自动切换,自动重试其他机器,常见于读操作
			
		2.failfast cluster模式
			一次调用失败就立即失败,常见于写操作
			
		3.failsafe cluster模式
			出现异常时忽略掉,常用于不重要的接口调用,比如记录日志
			
		4.failback cluster模式
			失败了后台自动记录请求,然后定时重发,比较适合于写消息对垒
			
		5.forking cluster模式
			并行调用多个provider,只要一个成功就立即返回
		
		6.broadcast cluster模式
			逐个调用所有的provider
	
	dubbo动态代理策略
	
		默认使用javassist动态字节码生成,创建代理类
		但是可以通过spi扩展机制配置自己的动态代理策略
	
	
	dubbo的SPI思想是什么?
		SPI,service provider interface,服务实现接口,一个接口有多个实现,你来配置哪个实现类来运行,运行时加载配置,创建该实现类的实例对象
		应用于插件扩展场景(例如jdbc)
		
	分布式系统的幂等性如何保证?
		1.每个请求必须有一个唯一的表示,比如订单支付请求,肯定包含订单id
		2.每次接收请求需要判断之前是否处理过该请求
		3.每次处理完请求,必须有一个记录标识这个请求处理过了
		
		例如:生成一个订单,用orderId作为唯一键,往数据库里先生成这个订单记录,后面用户重复发送这个请求时,数据库就会报错,整个事务就会回滚;也可以将标识写到redis中去,请求过来先去查redis,只有redis中标识这个请求没被处理过,才去处理请求
	
		
	分布式服务接口请求的顺序性如何保证?
		给操作同一个服务的请求设立同一个id,接入服务系统和实际处理请求的系统基于dubbo的consistanthash的策略进行hash分发,如果处理请求系统的服务是多线程的,则在系统内部在创建内存队列,保证同个id的请求能够放入同一个内存队列中,然后被同一线程执行,可以保证在不发生特殊情况下顺序性;如果要保证100%强顺序性,则需要用zookeeper分布式锁,这个对整个系统的消耗是巨大的
		
	分布式框架的设计思路
		1.上来你的服务就得去注册中心注册吧，你是不是得有个注册中心，保留各个服务的信心，可以用zookeeper来做，对吧
		2.然后你的消费者需要去注册中心拿对应的服务信息吧，对吧，而且每个服务可能会存在于多台机器上
		3.接着你就该发起一次请求了，咋发起？蒙圈了是吧。当然是基于动态代理了，你面向接口获取到一个动态代理，这个动态代理就是接口在本地的一个代理，然后这个代理会找到服务对应的机器地址
		4.然后找哪个机器发送请求？那肯定得有个负载均衡算法了，比如最简单的可以随机轮询是不是
		5.接着找到一台机器，就可以跟他发送请求了，第一个问题咋发送？你可以说用netty了，nio方式；第二个问题发送啥格式数据？你可以说用hessian序列化协议了，或者是别的，对吧。然后请求过去了。。
		6.服务器那边一样的，需要针对你自己的服务生成一个动态代理，监听某个网络端口了，然后代理你本地的服务代码。接收到请求的时候，就调用对应的服务代码，对吧。
		
	

	zookeeper的使用场景

		1.分布式协调
		让生产者知道消费者的处理结果.生产者发送请求到数据MQ之后,然后再ZK上注册监听器,一旦消费者消费完,消费者就立马可以收到通知
		
		2.分布式锁
		对某一个数据连续发出两次修改操作,但是两台机器同时收到请求,只能一台先执行,另外一台再执行,此时就用到分布式锁
		
		3.元数据/配置信息管理
		ZK可以作为很多系统的配置信息的管理,dubbo的注册中心,生产者将自己注册为服务,注册信息保存到ZK上,消费者去ZK上获取相应服务的地址
		
		4.HA高可用性
		Hadoop,HDFS等很多大数据系统,通过ZK感知来切换主备(类似于哨兵),来实现系统的高可用性
		
		
	分布式session方案
		我所了解的分布式session方案有两种:一种是tomcat+redis,主要是在tomcat的配置文件中配置一个RedisSessionManager,在里面配上redis的地址,这样就可以将Tomcat的session数据都存到redis中去,读的时候也去redis中去读;由于第一种方案会严重依赖tomcat,如果后期web容器迁移,还要重新配置,所以采用spring session + redis的方案,它也是基于redis来存储session数据,通过配置spring session的过滤器,将session的相关操作都交给spring session来管,而不用经过web容器
		
	分布式事务
		1.两阶段提交方案(XA方案)
		这个方案有一个事务管理器的概念,负责协调多个数据库的事务,事务管理器先去询问每个数据库,如果每个数据库都准备好了就正式提交事务,在各个数据库上执行数据;如果有一个数据库没准备好,就回滚事务.这种方案严重依赖数据库层面来搞定复杂的事务,效率低,不适用于高并发场景.而且这种方案会在一个系统内部出现直接跨多个库操作,违反微服务架构的规范,很容易导致自己的库被别人写挂.
		
		2.TCC方案(Try,Confirm,Cancel)
		Try:此阶段是对各个服务的资源做检测以及对资源进行锁定或者预留
		Confirm:此阶段是在各个服务中执行实际的操作
		Cancel:如果任何一个服务的业务执行出错,就要进行补偿,将已经执行成功的业务逻辑回滚操作
		这种方案的事务回滚实际上是依赖于自己写代码来回滚和补偿,补偿代码巨大,除了一些严格保证分布式事务的场景,比如和资金,订单相关的业务,尽量少使用
		
		3.本地消息表(ebay)
			1.A系统在自己本地一个事务里操作同时,插入一条数据到消息表
			2.A系统将这个消息发送到MQ中
			3.B系统接收到消息之后,在一个事务里,往自己本地消息表中插入一条数据,同时执行其他业务操作,如果这个消息已经被处理了,那么此时这个消息会回滚,这样保证不会重复处理消息
			4.B系统执行成功后,就会更新本地消息表的状态以及A系统消息表的状态
			5.如果B系统处理失败了,就不会更新消息表状态,A系统会定时扫描自己的消息表,没有处理的消息,会再次发送到MQ中,让B处理
			
		这个方案为了保证最终一致性,哪怕B事务失败了,A会不断重发消息,直到B成功为止;此外最大的问题是严重依赖数据库的消息表来管理事务,不适用高并发的场景,扩展性也差4
		
		4.可靠消息最终一致性方案
		这个方案是基于阿里的rocketMQ(3.3.6之前)来实现,是目前比较国内比较常用的方案
			1.A系统发送一个prepared消息到mq,如果prepared消息发送失败,就直接取消操作
			2.如果消息发送成功,就接着执行本地事务,如果成功就给mq发送确认消息,如果失败就告诉mq回滚消息
			3.如果发送了确认消息,B系统就会接收到,然后执行本地的事务
			4.mq会定时轮询所有prepared消息,回调接口,所有没发送确认消息的,问你继续重试还是回滚,然后A系统就去查看本地事务的状态,如果回滚,告诉mq回滚消息,如果成功了就重新发送确认消息
			5.如果B系统的事务失败,自动不断重试,直到成功,如果实在不行就让B系统本地回滚,然后想办法通知A系统也回滚,或者是发送警报由人工手动回滚和补偿
			
		5.最大努力通知方案
			1.A系统本地事务执行完后,发送消息到MQ
			2.有个服务会消费MQ中的消息,然后写入数据库记录下来,或者放入内存队列中,接着调用B系统的接口
			3.要是B系统执行成功就ok,执行失败,就最大努力通知服务定时尝试重新调用B系统,反复N次,实在不行就放弃
			
		tips:
		1.严格要求不能出错的场景,比如资金,使用TCC方案;如果一般分布式事务场景,可以用可靠消息最终一致性方案
		2.做好权衡,不要过分的追求分布式的100%消息一致性,过分地追求会导致代码复杂,开发时间长,系统性能差,吞吐量降低;99%的分布式接口调用,不要做分布式事务,直接就是监控,记录日志,事后快速地定位,排查和出解决方案,修复数据
			
		
		
		
		